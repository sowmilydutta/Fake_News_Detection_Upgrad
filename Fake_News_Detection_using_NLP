{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fake News Detection\n\n\n","metadata":{"id":"rhR-ZUkwJrFn"}},{"cell_type":"markdown","source":"## Objective\n","metadata":{"id":"hXeHUV5fJGiZ"}},{"cell_type":"markdown","source":"The objective of this assignment is to develop a Semantic Classification model. You will be using Word2Vec method to extract the semantic relations from the text and develop a basic understanding of how to train supervised models to categorise text based on its meaning, rather than just syntax. You will explore how this technique is used in situations where understanding textual meaning plays a critical role in making accurate and efficient decisions.\n","metadata":{"id":"kX73YZdgJIgF"}},{"cell_type":"markdown","source":"## Business Objective\n\nThe spread of fake news has become a significant challenge in today’s digital world. With the massive volume of news articles published daily, it’s becoming harder to distinguish between credible and misleading information. This creates a need for systems that can automatically classify news articles as true or fake, helping to reduce misinformation and protect public trust.\n\n\nIn this assignment, you will develop a Semantic Classification model that uses the Word2Vec method to detect recurring patterns and themes in news articles. Using supervised learning models, the goal is to build a system that classifies news articles as either fake or true.\n","metadata":{"id":"Gg_J6K8Xxfk2"}},{"cell_type":"markdown","source":"<h2> Pipelines that needs to be performed </h2>\n\nYou need to perform the following tasks to complete the assignment:\n\n<ol type=\"1\">\n\n  <li> Data Preparation\n  <li> Text Preprocessing\n  <li> Train Validation Split\n  <li> EDA on Training Data\n  <li> EDA on Validation Data [Optional]\n  <li> Feature Extraction\n  <li> Model Training and Evaluation\n\n</ol>","metadata":{"id":"ySqxOckxI4-F"}},{"cell_type":"markdown","source":"---","metadata":{"id":"gTxV-3GJUhWm"}},{"cell_type":"markdown","source":"**NOTE:** The marks given along with headings and sub-headings are cumulative marks for those particular headings/sub-headings.<br>\n\nThe actual marks for each task are specified within the tasks themselves.\n\nFor example, marks given with heading *2* or sub-heading *2.1* are the cumulative marks, for your reference only. <br>\n\nThe marks you will receive for completing tasks are given with the tasks.\n\nSuppose the marks for two tasks are: 3 marks for 2.1.1 and 2 marks for 3.2.2, or\n* 2.1.1 [3 marks]\n* 3.2.2 [2 marks]\n\nthen, you will earn 3 marks for completing task 2.1.1 and 2 marks for completing task 3.2.2.\n","metadata":{"id":"ofebI8ITG-Li"}},{"cell_type":"markdown","source":"---","metadata":{"id":"YdQjht7dUiHt"}},{"cell_type":"markdown","source":"## Data Dictionary\n","metadata":{"id":"8b1lNTpKF54T"}},{"cell_type":"markdown","source":"For this assignment, you will work with two datasets, `True.csv` and `Fake.csv`.\nBoth datasets contain three columns:\n<ul>\n  <li> title of the news article\n  <li> text of the news article\n  <li> date of article publication\n</ul>\n\n`True.csv` dataset includes 21,417 true news, while the `Fake.csv` dataset comprises 23,502 fake news.","metadata":{"id":"43j_A_GsI9TS"}},{"cell_type":"markdown","source":"## Installing required Libraries","metadata":{"id":"_oTQwQ_Rh4nT"}},{"cell_type":"code","source":"# # !pip install --upgrade numpy==1.26.4\n# # !pip install --upgrade pandas==2.2.2\n# !pip install --upgrade nltk==3.9.1\n# !pip install --upgrade spacy==3.7.5\n# !pip install --upgrade scipy==1.12\n# !pip install --upgrade pydantic==2.10.5\n# !pip install wordcloud==1.9.4\n# !python -m spacy download en_core_web_sm\n# # !pip install cuda\n# # !pip install cupy-cuda11x","metadata":{"id":"lIY57QOLiCA2","scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:44:48.007792Z","iopub.execute_input":"2025-04-27T12:44:48.008036Z","iopub.status.idle":"2025-04-27T12:44:48.012676Z","shell.execute_reply.started":"2025-04-27T12:44:48.008011Z","shell.execute_reply":"2025-04-27T12:44:48.011827Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Importing the necessary libraries","metadata":{"id":"JuLFIymAL58u"}},{"cell_type":"code","source":"# Import essential libraries for data manipulation and analysis\nimport numpy as np  # For numerical operations and arrays\nimport pandas as pd  # For working with dataframes and structured data\nimport re  # For regular expression operations (text processing)\nimport nltk  # Natural Language Toolkit for text processing\nimport spacy  # For advanced NLP tasks\nimport string  # For handling string-related operations\n\n# Optional: Uncomment the line below to enable GPU support for spaCy (if you have a compatible GPU)\nspacy.require_gpu()\n\n# Load the spaCy small English language model\nnlp = spacy.load(\"en_core_web_sm\")\n\n# For data visualization\nimport seaborn as sns  # Data visualization library for statistical graphics\nimport matplotlib.pyplot as plt  # Matplotlib for creating static plots\n# Configure Matplotlib to display plots inline in Jupyter Notebook\n%matplotlib inline\n\n# Suppress unnecessary warnings to keep output clean\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# For interactive plots\nfrom plotly.offline import plot  # Enables offline plotting with Plotly\nimport plotly.graph_objects as go  # For creating customizable Plotly plots\nimport plotly.express as px  # A high-level interface for Plotly\n\n# For preprocessing and feature extraction in machine learning\nfrom sklearn.feature_extraction.text import (  # Methods for text vectorization\n    CountVectorizer,  # Converts text into a bag-of-words model\n)\n\n# Import accuracy, precision, recall, f_score from sklearn to predict train accuracy\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Pretty printing for better readability of output\nfrom pprint import pprint\n\n# For progress tracking in loops (useful for larger datasets)\nfrom tqdm import tqdm, tqdm_notebook  # Progress bar for loops\ntqdm.pandas()  # Enables progress bars for pandas operations\n","metadata":{"id":"O-Q9pqrcJrFr","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:44:48.013363Z","iopub.execute_input":"2025-04-27T12:44:48.013563Z","iopub.status.idle":"2025-04-27T12:44:59.223984Z","shell.execute_reply.started":"2025-04-27T12:44:48.013547Z","shell.execute_reply":"2025-04-27T12:44:59.223181Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"## Change the display properties of pandas to max\n# pd.set_option('display.max_colwidth', None)\n# pd.set_option('display.max_columns', None)\n# pd.set_option('display.max_rows', None)","metadata":{"id":"s8Le3OfjI666","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:44:59.225927Z","iopub.execute_input":"2025-04-27T12:44:59.226344Z","iopub.status.idle":"2025-04-27T12:44:59.229749Z","shell.execute_reply.started":"2025-04-27T12:44:59.226325Z","shell.execute_reply":"2025-04-27T12:44:59.228995Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Load the data\n\nLoad the True.csv and Fake.csv files as DataFrames","metadata":{"id":"KtRLCsNVJrFt"}},{"cell_type":"code","source":"# Import the first file - True.csv\ntrue = pd.read_csv(\"/kaggle/input/fake-news-detection-dataset/True.csv\")\n# Import the second file - Fake.csv\nfake = pd.read_csv(\"/kaggle/input/fake-news-detection-dataset/Fake.csv\")","metadata":{"id":"puVzIf_iJrFt","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:44:59.230432Z","iopub.execute_input":"2025-04-27T12:44:59.230748Z","iopub.status.idle":"2025-04-27T12:45:01.487374Z","shell.execute_reply.started":"2025-04-27T12:44:59.230724Z","shell.execute_reply":"2025-04-27T12:45:01.486818Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## **1.** Data Preparation  <font color = red>[10 marks]</font>\n\n\n\n","metadata":{"id":"_xYpH-sAJrFu"}},{"cell_type":"markdown","source":"### **1.0** Data Understanding","metadata":{"id":"A2fTeYJImEv7"}},{"cell_type":"code","source":"# Inspect the DataFrame with True News to understand the given data\ntrue.head()","metadata":{"id":"Lf8ufHH5JrFu","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.488101Z","iopub.execute_input":"2025-04-27T12:45:01.488364Z","iopub.status.idle":"2025-04-27T12:45:01.507856Z","shell.execute_reply.started":"2025-04-27T12:45:01.488341Z","shell.execute_reply":"2025-04-27T12:45:01.507143Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                               title  \\\n0  As U.S. budget fight looms, Republicans flip t...   \n1  U.S. military to accept transgender recruits o...   \n2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n3  FBI Russia probe helped by Australian diplomat...   \n4  Trump wants Postal Service to charge 'much mor...   \n\n                                                text                date  \n0  WASHINGTON (Reuters) - The head of a conservat...  December 31, 2017   \n1  WASHINGTON (Reuters) - Transgender people will...  December 29, 2017   \n2  WASHINGTON (Reuters) - The special counsel inv...  December 31, 2017   \n3  WASHINGTON (Reuters) - Trump campaign adviser ...  December 30, 2017   \n4  SEATTLE/WASHINGTON (Reuters) - President Donal...  December 29, 2017   ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As U.S. budget fight looms, Republicans flip t...</td>\n      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n      <td>December 31, 2017</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S. military to accept transgender recruits o...</td>\n      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n      <td>December 29, 2017</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n      <td>December 31, 2017</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FBI Russia probe helped by Australian diplomat...</td>\n      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n      <td>December 30, 2017</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Trump wants Postal Service to charge 'much mor...</td>\n      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n      <td>December 29, 2017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Inspect the DataFrame with Fake News to understand the given data\nfake.head()","metadata":{"id":"gI7X0Voh6h7r","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.508621Z","iopub.execute_input":"2025-04-27T12:45:01.508912Z","iopub.status.idle":"2025-04-27T12:45:01.561782Z","shell.execute_reply.started":"2025-04-27T12:45:01.508887Z","shell.execute_reply":"2025-04-27T12:45:01.561088Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                               title  \\\n0   Donald Trump Sends Out Embarrassing New Year’...   \n1   Drunk Bragging Trump Staffer Started Russian ...   \n2   Sheriff David Clarke Becomes An Internet Joke...   \n3   Trump Is So Obsessed He Even Has Obama’s Name...   \n4   Pope Francis Just Called Out Donald Trump Dur...   \n\n                                                text               date  \n0  Donald Trump just couldn t wish all Americans ...  December 31, 2017  \n1  House Intelligence Committee Chairman Devin Nu...  December 31, 2017  \n2  On Friday, it was revealed that former Milwauk...  December 30, 2017  \n3  On Christmas day, Donald Trump announced that ...  December 29, 2017  \n4  Pope Francis used his annual Christmas Day mes...  December 25, 2017  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n      <td>Donald Trump just couldn t wish all Americans ...</td>\n      <td>December 31, 2017</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n      <td>House Intelligence Committee Chairman Devin Nu...</td>\n      <td>December 31, 2017</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n      <td>On Friday, it was revealed that former Milwauk...</td>\n      <td>December 30, 2017</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n      <td>On Christmas day, Donald Trump announced that ...</td>\n      <td>December 29, 2017</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n      <td>Pope Francis used his annual Christmas Day mes...</td>\n      <td>December 25, 2017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Print the column details for True News DataFrame\ntrue.info()","metadata":{"id":"Dwcty-wmJrFw","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.562457Z","iopub.execute_input":"2025-04-27T12:45:01.562673Z","iopub.status.idle":"2025-04-27T12:45:01.596011Z","shell.execute_reply.started":"2025-04-27T12:45:01.562657Z","shell.execute_reply":"2025-04-27T12:45:01.595457Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 21417 entries, 0 to 21416\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   title   21417 non-null  object\n 1   text    21417 non-null  object\n 2   date    21417 non-null  object\ndtypes: object(3)\nmemory usage: 502.1+ KB\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Print the column details for Fake News Dataframe\nfake.info()","metadata":{"id":"EPLAnUMjjzQ4","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.596591Z","iopub.execute_input":"2025-04-27T12:45:01.596795Z","iopub.status.idle":"2025-04-27T12:45:01.618709Z","shell.execute_reply.started":"2025-04-27T12:45:01.596779Z","shell.execute_reply":"2025-04-27T12:45:01.617983Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 23523 entries, 0 to 23522\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   title   23502 non-null  object\n 1   text    23502 non-null  object\n 2   date    23481 non-null  object\ndtypes: object(3)\nmemory usage: 551.4+ KB\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Print the column names of both DataFrames\nprint(\"Columns for True.csv:\", true.columns)\nprint(\"Columns for Fake.csv:\", fake.columns)","metadata":{"id":"dyuDFzPkI67B","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.621353Z","iopub.execute_input":"2025-04-27T12:45:01.621554Z","iopub.status.idle":"2025-04-27T12:45:01.634848Z","shell.execute_reply.started":"2025-04-27T12:45:01.621538Z","shell.execute_reply":"2025-04-27T12:45:01.634082Z"}},"outputs":[{"name":"stdout","text":"Columns for True.csv: Index(['title', 'text', 'date'], dtype='object')\nColumns for Fake.csv: Index(['title', 'text', 'date'], dtype='object')\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### **1.1** Add new column  <font color = red>[3 marks]</font> <br>\n\nAdd new column `news_label` to both the DataFrames and assign labels","metadata":{"id":"h2fff1S7hq5h"}},{"cell_type":"code","source":"# Add a new column 'news_label' to the true news DataFrame and assign the label \"1\" to indicate that these news are true\ntrue['news_label'] = 1\n# Add a new column 'news_label' to the fake news DataFrame and assign the label \"0\" to indicate that these news are fake\nfake['news_label'] = 0","metadata":{"id":"YOu_KhbH78du","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.635583Z","iopub.execute_input":"2025-04-27T12:45:01.635842Z","iopub.status.idle":"2025-04-27T12:45:01.650177Z","shell.execute_reply.started":"2025-04-27T12:45:01.635822Z","shell.execute_reply":"2025-04-27T12:45:01.649297Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(\"Columns for True.csv:\", true.columns)\nprint(\"Columns for Fake.csv:\", fake.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.651054Z","iopub.execute_input":"2025-04-27T12:45:01.651334Z","iopub.status.idle":"2025-04-27T12:45:01.667073Z","shell.execute_reply.started":"2025-04-27T12:45:01.651310Z","shell.execute_reply":"2025-04-27T12:45:01.666434Z"}},"outputs":[{"name":"stdout","text":"Columns for True.csv: Index(['title', 'text', 'date', 'news_label'], dtype='object')\nColumns for Fake.csv: Index(['title', 'text', 'date', 'news_label'], dtype='object')\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"### **1.2** Merge DataFrames  <font color = red>[2 marks]</font> <br>\n\nCreate a new Dataframe by merging True and Fake DataFrames","metadata":{"id":"UShuo3h54DAh"}},{"cell_type":"code","source":"# Combine the true and fake news DataFrames into a single DataFrame\nnews = pd.concat([true, fake], axis=0)","metadata":{"id":"5GX_QMy04M4-","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.667838Z","iopub.execute_input":"2025-04-27T12:45:01.668067Z","iopub.status.idle":"2025-04-27T12:45:01.684052Z","shell.execute_reply.started":"2025-04-27T12:45:01.668042Z","shell.execute_reply":"2025-04-27T12:45:01.683470Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Display the first 5 rows of the combined DataFrame to verify the result\nnews.sample(n=5)","metadata":{"id":"FYCtKXD1JrFw","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.684664Z","iopub.execute_input":"2025-04-27T12:45:01.684881Z","iopub.status.idle":"2025-04-27T12:45:01.697732Z","shell.execute_reply.started":"2025-04-27T12:45:01.684867Z","shell.execute_reply":"2025-04-27T12:45:01.697160Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                                   title  \\\n17160  SHERIFFS, LT. GOV AND IMMIGRATION EXPERTS FIGH...   \n22504      Is Hillary’s Meltdown Real, or a Staged Exit?   \n16129  MYSTERY SURROUNDS Funding For Take Down Of His...   \n12508  WOW! HILLARY CAUGHT ON VIDEO In 2000 Saying Sh...   \n13445  U.N. seeks urgent medical evacuation of 500 fr...   \n\n                                                    text                date  \\\n17160  Hello America Are we awake yet?AUSTIN, Texas  ...         Aug 7, 2015   \n22504  21st Century Wire says As shocking and controv...  September 14, 2016   \n16129  The mayor of New Orleans is being evasive on w...        Apr 27, 2017   \n12508  Too bad for Hillary she wasn t actually tellin...         Nov 4, 2016   \n13445  GENEVA (Reuters) - The United Nations called o...  November 30, 2017    \n\n       news_label  \n17160           0  \n22504           0  \n16129           0  \n12508           0  \n13445           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>date</th>\n      <th>news_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17160</th>\n      <td>SHERIFFS, LT. GOV AND IMMIGRATION EXPERTS FIGH...</td>\n      <td>Hello America Are we awake yet?AUSTIN, Texas  ...</td>\n      <td>Aug 7, 2015</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22504</th>\n      <td>Is Hillary’s Meltdown Real, or a Staged Exit?</td>\n      <td>21st Century Wire says As shocking and controv...</td>\n      <td>September 14, 2016</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16129</th>\n      <td>MYSTERY SURROUNDS Funding For Take Down Of His...</td>\n      <td>The mayor of New Orleans is being evasive on w...</td>\n      <td>Apr 27, 2017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12508</th>\n      <td>WOW! HILLARY CAUGHT ON VIDEO In 2000 Saying Sh...</td>\n      <td>Too bad for Hillary she wasn t actually tellin...</td>\n      <td>Nov 4, 2016</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13445</th>\n      <td>U.N. seeks urgent medical evacuation of 500 fr...</td>\n      <td>GENEVA (Reuters) - The United Nations called o...</td>\n      <td>November 30, 2017</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"### **1.3** Handle the null values  <font color = red>[2 marks]</font> <br>\n\nCheck for null values and handle it by imputation or dropping the null values","metadata":{"id":"IphUaBu3oFZK"}},{"cell_type":"code","source":"# Check Presence of Null Values\nprint(news.isnull().sum())","metadata":{"id":"4FRDxOo6r51j","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.698460Z","iopub.execute_input":"2025-04-27T12:45:01.698948Z","iopub.status.idle":"2025-04-27T12:45:01.713354Z","shell.execute_reply.started":"2025-04-27T12:45:01.698925Z","shell.execute_reply":"2025-04-27T12:45:01.712626Z"}},"outputs":[{"name":"stdout","text":"title         21\ntext          21\ndate          42\nnews_label     0\ndtype: int64\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Handle Rows with Null Values\nnews_cleaned = news.dropna(subset=['date', 'title', 'text'], thresh=2)","metadata":{"id":"eiwvoyfYr6EB","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.714348Z","iopub.execute_input":"2025-04-27T12:45:01.714584Z","iopub.status.idle":"2025-04-27T12:45:01.750614Z","shell.execute_reply.started":"2025-04-27T12:45:01.714560Z","shell.execute_reply":"2025-04-27T12:45:01.750124Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(news_cleaned.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.751238Z","iopub.execute_input":"2025-04-27T12:45:01.751411Z","iopub.status.idle":"2025-04-27T12:45:01.763103Z","shell.execute_reply.started":"2025-04-27T12:45:01.751397Z","shell.execute_reply":"2025-04-27T12:45:01.762469Z"}},"outputs":[{"name":"stdout","text":"title          0\ntext           0\ndate          21\nnews_label     0\ndtype: int64\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"### **1.4** Merge the relevant columns and drop the rest from the DataFrame  <font color = red>[3 marks]</font> <br>\n\nCombine the relevant columns into a new column `news_text` and then drop irrelevant columns from the DataFrame","metadata":{"id":"kDyPvMITooWA"}},{"cell_type":"code","source":"# Combine the relevant columns into a new column 'news_text' by joining their values with a space\nnews_cleaned[\"news_text\"] = news_cleaned[\"title\"]+ \" \" + news_cleaned[\"text\"]","metadata":{"id":"u9VI48jS_HTy","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.763927Z","iopub.execute_input":"2025-04-27T12:45:01.764191Z","iopub.status.idle":"2025-04-27T12:45:01.942411Z","shell.execute_reply.started":"2025-04-27T12:45:01.764168Z","shell.execute_reply":"2025-04-27T12:45:01.941586Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"news_cleaned.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.943278Z","iopub.execute_input":"2025-04-27T12:45:01.943543Z","iopub.status.idle":"2025-04-27T12:45:01.968221Z","shell.execute_reply.started":"2025-04-27T12:45:01.943517Z","shell.execute_reply":"2025-04-27T12:45:01.967473Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 44919 entries, 0 to 23522\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   title       44919 non-null  object\n 1   text        44919 non-null  object\n 2   date        44898 non-null  object\n 3   news_label  44919 non-null  int64 \n 4   news_text   44919 non-null  object\ndtypes: int64(1), object(4)\nmemory usage: 2.1+ MB\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Drop the irrelevant columns from the DataFrame as they are no longer needed\nnews_cleaned = news_cleaned[[\"news_text\", \"news_label\"]]","metadata":{"id":"u9VI48jS_HTy","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.969060Z","iopub.execute_input":"2025-04-27T12:45:01.969265Z","iopub.status.idle":"2025-04-27T12:45:01.983450Z","shell.execute_reply.started":"2025-04-27T12:45:01.969250Z","shell.execute_reply":"2025-04-27T12:45:01.982939Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Display the first 5 rows of the updated DataFrame to check the result\nnews_cleaned.head()","metadata":{"id":"u9VI48jS_HTy","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:01.984273Z","iopub.execute_input":"2025-04-27T12:45:01.984521Z","iopub.status.idle":"2025-04-27T12:45:02.001423Z","shell.execute_reply.started":"2025-04-27T12:45:01.984500Z","shell.execute_reply":"2025-04-27T12:45:02.000657Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                           news_text  news_label\n0  As U.S. budget fight looms, Republicans flip t...           1\n1  U.S. military to accept transgender recruits o...           1\n2  Senior U.S. Republican senator: 'Let Mr. Muell...           1\n3  FBI Russia probe helped by Australian diplomat...           1\n4  Trump wants Postal Service to charge 'much mor...           1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>news_text</th>\n      <th>news_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As U.S. budget fight looms, Republicans flip t...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S. military to accept transgender recruits o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FBI Russia probe helped by Australian diplomat...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Trump wants Postal Service to charge 'much mor...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"## **2.** Text Preprocessing <font color = red>[15 marks]</font> <br>\n\n\n\n\n\n\nOn all the news text, you need to:\n<ol type=1>\n  <li> Make the text lowercase\n  <li> Remove text in square brackets\n  <li> Remove punctuation\n  <li> Remove words containing numbers\n</ol>\n\n\nOnce you have done these cleaning operations you need to perform POS tagging and lemmatization on the cleaned news text, and remove all words that are not tagged as NN or NNS.","metadata":{"id":"L944HZpsJrFy"}},{"cell_type":"markdown","source":"### **2.1** Text Cleaning  <font color = red>[5 marks]</font> <br>\n\n","metadata":{"id":"_-6VW3V3jx1A"}},{"cell_type":"markdown","source":"#### 2.1.0 Create a new DataFrame to store the processed data\n\n","metadata":{"id":"78OZs7P4kp41"}},{"cell_type":"code","source":"# Create a DataFrame('df_clean') that will have only the cleaned news text and the lemmatized news text with POS tags removed\ndf_clean = pd.DataFrame()\n# Add 'news_label' column to the new dataframe for topic identification\ndf_clean[\"news_label\"] = news_cleaned[\"news_label\"]","metadata":{"id":"uXnN7aa_JrF0","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:02.002179Z","iopub.execute_input":"2025-04-27T12:45:02.002452Z","iopub.status.idle":"2025-04-27T12:45:02.021953Z","shell.execute_reply.started":"2025-04-27T12:45:02.002433Z","shell.execute_reply":"2025-04-27T12:45:02.021362Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"#### 2.1.1 Write the function to clean the text and remove all the unnecessary elements  <font color = red>[4 marks]</font> <br>\n\n","metadata":{"id":"hsf00J83mdNL"}},{"cell_type":"code","source":"# Write the function here to clean the text and remove all the unnecessary elements\nimport re\nimport string\n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'\\[.*?\\]', '', text)\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    text = re.sub(r'\\w*\\d\\w*', '', text)\n    \n    return text","metadata":{"id":"qm7SjjSkJrFz","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:02.022713Z","iopub.execute_input":"2025-04-27T12:45:02.022920Z","iopub.status.idle":"2025-04-27T12:45:02.038114Z","shell.execute_reply.started":"2025-04-27T12:45:02.022906Z","shell.execute_reply":"2025-04-27T12:45:02.037327Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"#### 2.1.2  Apply the function to clean the news text and store the cleaned text in a new column within the new DataFrame. <font color = red>[1 mark]</font> <br>\n","metadata":{"id":"dDFMNnrdkUvd"}},{"cell_type":"code","source":"# Apply the function to clean the news text and remove all unnecessary elements\n# Store it in a separate column in the new DataFrame\ndf_clean['cleaned_text'] = news_cleaned['news_text'].apply(clean_text)","metadata":{"id":"nOiDVvEIJrF0","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:02.038919Z","iopub.execute_input":"2025-04-27T12:45:02.039108Z","iopub.status.idle":"2025-04-27T12:45:23.270986Z","shell.execute_reply.started":"2025-04-27T12:45:02.039093Z","shell.execute_reply":"2025-04-27T12:45:23.270139Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"### **2.2** POS Tagging and Lemmatization  <font color = red>[10 marks]</font> <br>\n\n","metadata":{"id":"MSAVnSelkF9d"}},{"cell_type":"markdown","source":"#### 2.2.1 Write the function for POS tagging and lemmatization, filtering stopwords and keeping only NN and NNS tags <font color = red>[8 marks]</font> <br>\n\n","metadata":{"id":"QCqNHDL2mHok"}},{"cell_type":"code","source":"# Write the function for POS tagging and lemmatization, filtering stopwords and keeping only NN and NNS tags\nimport spacy\nfrom nltk.corpus import stopwords\n\n# Load spacy model\nnlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\",\"ner\"])\nstop_words = set(stopwords.words('english'))\n\ndef pos_tag_lemmatize(text):\n    doc = nlp(text)\n    tokens = []\n    for token in doc:\n        # Check if token is a noun (NN or NNS), not a stopword, and not punctuation\n        if (token.tag_ in ['NN', 'NNS']) and (token.text.lower() not in stop_words) and (token.is_alpha):\n            tokens.append(token.lemma_.lower())  # Lemmatize and convert to lowercase\n    return \" \".join(tokens)\n","metadata":{"id":"zgOu8t8HJrFz","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:23.271846Z","iopub.execute_input":"2025-04-27T12:45:23.272133Z","iopub.status.idle":"2025-04-27T12:45:24.015558Z","shell.execute_reply.started":"2025-04-27T12:45:23.272110Z","shell.execute_reply":"2025-04-27T12:45:24.014812Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"#### 2.2.2  Apply the POS tagging and lemmatization function to cleaned text and store it in a new column within the new DataFrame. <font color = red>[2 mark]</font> <br>\n\n**NOTE: Store the cleaned text and the lemmatized text with POS tags removed in separate columns within the new DataFrame.**\n\n**This will be useful for analysing character length differences between cleaned text and lemmatized text with POS tags removed during EDA.**\n","metadata":{"id":"_T3So7PXlibT"}},{"cell_type":"code","source":"# Apply POS tagging and lemmatization function to cleaned text\n# Store it in a separate column in the new DataFrame\ndf_clean['lemmatized_text'] = df_clean['cleaned_text'].apply(pos_tag_lemmatize)","metadata":{"id":"L9FWmibNI67F","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:45:24.016412Z","iopub.execute_input":"2025-04-27T12:45:24.016674Z","iopub.status.idle":"2025-04-27T12:57:50.950465Z","shell.execute_reply.started":"2025-04-27T12:45:24.016651Z","shell.execute_reply":"2025-04-27T12:57:50.949807Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"### Save the Cleaned data as a csv file (Recommended)","metadata":{"id":"BMc5kjeqnX9b"}},{"cell_type":"code","source":"## Recommended to perform the below steps to save time while rerunning the code\ndf_clean.to_csv(\"/kaggle/working/clean_df.csv\", index=False)\ndf_clean = pd.read_csv(\"/kaggle/working/clean_df.csv\")","metadata":{"id":"fTjNG5xfnlwm","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:50.951368Z","iopub.execute_input":"2025-04-27T12:57:50.951598Z","iopub.status.idle":"2025-04-27T12:57:56.734593Z","shell.execute_reply.started":"2025-04-27T12:57:50.951578Z","shell.execute_reply":"2025-04-27T12:57:56.734043Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Check the first few rows of the DataFrame\ndf_clean.head()","metadata":{"id":"0M0LseVjneMv","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.748095Z","iopub.execute_input":"2025-04-27T12:57:56.748343Z","iopub.status.idle":"2025-04-27T12:57:56.755981Z","shell.execute_reply.started":"2025-04-27T12:57:56.748325Z","shell.execute_reply":"2025-04-27T12:57:56.755327Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"   news_label                                       cleaned_text  \\\n0           1  as us budget fight looms republicans flip thei...   \n1           1  us military to accept transgender recruits on ...   \n2           1  senior us republican senator let mr mueller do...   \n3           1  fbi russia probe helped by australian diplomat...   \n4           1  trump wants postal service to charge much more...   \n\n                                     lemmatized_text  \n0  budget fight script head faction month expansi...  \n1  military transgender recruit people time milit...  \n2  mueller job counsel investigation link electio...  \n3  probe diplomat trump campaign adviser diplomat...  \n4  trump service service ship package amzno fight...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>news_label</th>\n      <th>cleaned_text</th>\n      <th>lemmatized_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>as us budget fight looms republicans flip thei...</td>\n      <td>budget fight script head faction month expansi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>us military to accept transgender recruits on ...</td>\n      <td>military transgender recruit people time milit...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>senior us republican senator let mr mueller do...</td>\n      <td>mueller job counsel investigation link electio...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>fbi russia probe helped by australian diplomat...</td>\n      <td>probe diplomat trump campaign adviser diplomat...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>trump wants postal service to charge much more...</td>\n      <td>trump service service ship package amzno fight...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# Check the dimensions of the DataFrame\ndf_clean.shape","metadata":{"id":"lDZq_T3FYuOi","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.756769Z","iopub.execute_input":"2025-04-27T12:57:56.757019Z","iopub.status.idle":"2025-04-27T12:57:56.775705Z","shell.execute_reply.started":"2025-04-27T12:57:56.756996Z","shell.execute_reply":"2025-04-27T12:57:56.775020Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"(44919, 3)"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# Check the number of non-null entries and data types of each column\nprint(df_clean.isnull().sum())","metadata":{"id":"ah1aJPmiAqWz","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:59:00.962097Z","iopub.execute_input":"2025-04-27T12:59:00.962417Z","iopub.status.idle":"2025-04-27T12:59:00.979581Z","shell.execute_reply.started":"2025-04-27T12:59:00.962399Z","shell.execute_reply":"2025-04-27T12:59:00.978955Z"}},"outputs":[{"name":"stdout","text":"news_label          0\ncleaned_text        0\nlemmatized_text    16\ndtype: int64\n","output_type":"stream"}],"execution_count":67},{"cell_type":"markdown","source":"## **3.** Train Validation Split <font color = red>[5 marks]</font> <br>","metadata":{"id":"XMzqKme_2QQ0"}},{"cell_type":"code","source":"# Import Train Test Split and split the DataFrame into 70% train and 30% validation data\n","metadata":{"id":"jmx_W7Ty2PlK","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.797883Z","iopub.execute_input":"2025-04-27T12:57:56.798130Z","iopub.status.idle":"2025-04-27T12:57:56.810786Z","shell.execute_reply.started":"2025-04-27T12:57:56.798110Z","shell.execute_reply":"2025-04-27T12:57:56.810106Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"## **4.** Exploratory Data Analysis on Training Data  <font color = red>[40 marks]</font> <br>\n\nPerform EDA on cleaned and preprocessed texts to get familiar with the training data by performing the tasks given below:\n\n<ul>\n  <li> Visualise the training data according to the character length of cleaned news text and lemmatized news text with POS tags removed\n  <li> Using a word cloud, find the top 40 words by frequency in true and fake news separately\n  <li> Find the top unigrams, bigrams and trigrams by frequency in true and fake news separately\n</ul>\n\n\n\n","metadata":{"id":"_7Un1AElJrF2"}},{"cell_type":"markdown","source":"### **4.1** Visualise character lengths of cleaned news text and lemmatized news text with POS tags removed  <font color = red>[10 marks]</font> <br>\n\n","metadata":{"id":"rOZ7yZ4Fp1cp"}},{"cell_type":"markdown","source":"##### 4.1.1  Add new columns to calculate the character lengths of the processed data columns  <font color = red>[3 marks]</font> <br>\n\n","metadata":{"id":"UCI4DbZWpQ7n"}},{"cell_type":"code","source":"# Add a new column to calculate the character length of cleaned news text\n\n# Add a new column to calculate the character length of lemmatized news text with POS tags removed\n","metadata":{"id":"HifHm5rxpaxZ","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.811475Z","iopub.execute_input":"2025-04-27T12:57:56.811716Z","iopub.status.idle":"2025-04-27T12:57:56.826318Z","shell.execute_reply.started":"2025-04-27T12:57:56.811675Z","shell.execute_reply":"2025-04-27T12:57:56.825745Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"##### 4.1.2  Create Histogram to visualise character lengths  <font color = red>[7 marks]</font> <br>\n\n Plot both distributions on the same graph for comparison and to observe overlaps and peak differences to understand text preprocessing's impact on text length.","metadata":{"id":"U1JvT8lNpbFe"}},{"cell_type":"code","source":"# Create a histogram plot to visualise character lengths\n\n# Add histogram for cleaned news text\n\n# Add histogram for lemmatized news text with POS tags removed\n","metadata":{"id":"q-zaqJF6JrF2","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.827063Z","iopub.execute_input":"2025-04-27T12:57:56.827232Z","iopub.status.idle":"2025-04-27T12:57:56.843060Z","shell.execute_reply.started":"2025-04-27T12:57:56.827219Z","shell.execute_reply":"2025-04-27T12:57:56.842402Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"### **4.2** Find and display the top 40 words by frequency among true and fake news in Training data after processing the text  <font color = red>[10 marks]</font> <br>\n\n","metadata":{"id":"T9jD_6SeJrF3"}},{"cell_type":"markdown","source":"##### 4.2.1 Find and display the top 40 words by frequency among true news in Training data after processing the text  <font color = red>[5 marks]</font> <br>","metadata":{"id":"n320yzDiEUH4"}},{"cell_type":"code","source":"## Use a word cloud find the top 40 words by frequency among true news in the training data after processing the text\n\n# Filter news with label 1 (True News) and convert to it string and handle any non-string values\n\n# Generate word cloud for True News\n","metadata":{"id":"QcfdvtfZJrF3","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.843828Z","iopub.execute_input":"2025-04-27T12:57:56.844092Z","iopub.status.idle":"2025-04-27T12:57:56.857487Z","shell.execute_reply.started":"2025-04-27T12:57:56.844076Z","shell.execute_reply":"2025-04-27T12:57:56.856816Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"##### 4.2.2 Find and display the top 40 words by frequency among fake news in Training data after processing the text  <font color = red>[5 marks]</font> <br>","metadata":{"id":"LbHtjWzbEj__"}},{"cell_type":"code","source":"## Use a word cloud find the top 40 words by frequency among fake news in the training data after processing the text\n\n# Filter news with label 0 (Fake News) and convert to it string and handle any non-string values\n\n# Generate word cloud for Fake News\n","metadata":{"id":"MOFoDEscEkMO","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.858187Z","iopub.execute_input":"2025-04-27T12:57:56.858371Z","iopub.status.idle":"2025-04-27T12:57:56.873056Z","shell.execute_reply.started":"2025-04-27T12:57:56.858356Z","shell.execute_reply":"2025-04-27T12:57:56.872191Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"### **4.3** Find and display the top unigrams, bigrams and trigrams by frequency in true news and fake news after processing the text  <font color = red>[20 marks]</font> <br>\n\n\n","metadata":{"id":"5DfCSbbmJrF4"}},{"cell_type":"markdown","source":"##### 4.3.1 Write a function to get the specified top n-grams  <font color = red>[4 marks]</font> <br>\n\n","metadata":{"id":"ApGagSppsAyL"}},{"cell_type":"code","source":"# Write a function to get the specified top n-grams\n","metadata":{"id":"5mbk5DS5JrF4","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.873839Z","iopub.execute_input":"2025-04-27T12:57:56.874067Z","iopub.status.idle":"2025-04-27T12:57:56.887441Z","shell.execute_reply.started":"2025-04-27T12:57:56.874045Z","shell.execute_reply":"2025-04-27T12:57:56.886743Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"##### 4.3.2 Handle the NaN values  <font color = red>[1 mark]</font> <br>\n\n","metadata":{"id":"ZHcBL7vRsM4I"}},{"cell_type":"code","source":"# Handle NaN values in the text data\n","metadata":{"id":"3Ks69UQGCXpw","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.888181Z","iopub.execute_input":"2025-04-27T12:57:56.888378Z","iopub.status.idle":"2025-04-27T12:57:56.902387Z","shell.execute_reply.started":"2025-04-27T12:57:56.888364Z","shell.execute_reply":"2025-04-27T12:57:56.901575Z"}},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"### For True News\n\n\n","metadata":{"id":"caioIgIEsfh2"}},{"cell_type":"markdown","source":"##### 4.3.3 Display the top 10 unigrams by frequency in true news and plot them as a bar graph  <font color = red>[2.5 marks]</font> <br>","metadata":{"id":"QYB2ZXZ83fjo"}},{"cell_type":"code","source":"# Print the top 10 unigrams by frequency in true news and plot the same using a bar graph\n","metadata":{"id":"YX7fedm1JrF8","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.902927Z","iopub.execute_input":"2025-04-27T12:57:56.903112Z","iopub.status.idle":"2025-04-27T12:57:56.916509Z","shell.execute_reply.started":"2025-04-27T12:57:56.903097Z","shell.execute_reply":"2025-04-27T12:57:56.915850Z"}},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":"##### 4.3.4 Display the top 10 bigrams by frequency in true news and plot them as a bar graph  <font color = red>[2.5 marks]</font> <br>\n\n","metadata":{"id":"y3Q7wQnnsvOE"}},{"cell_type":"code","source":"# Print the top 10 bigrams by frequency in true news and plot the same using a bar graph\n","metadata":{"id":"aV7kD7w8JrF8","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.917237Z","iopub.execute_input":"2025-04-27T12:57:56.917443Z","iopub.status.idle":"2025-04-27T12:57:56.930348Z","shell.execute_reply.started":"2025-04-27T12:57:56.917429Z","shell.execute_reply":"2025-04-27T12:57:56.929726Z"}},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"##### 4.3.5 Display the top 10 trigrams by frequency in true news and plot them as a bar graph  <font color = red>[2.5 marks]</font> <br>\n\n","metadata":{"id":"opdM04-Bs_Bg"}},{"cell_type":"code","source":"# Print the top 10 trigrams by frequency in true news and plot the same using a bar graph\n","metadata":{"id":"Xkh7vtbtJrF-","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.930966Z","iopub.execute_input":"2025-04-27T12:57:56.931154Z","iopub.status.idle":"2025-04-27T12:57:56.944431Z","shell.execute_reply.started":"2025-04-27T12:57:56.931140Z","shell.execute_reply":"2025-04-27T12:57:56.943802Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"### For Fake News\n\n\n\n\n\n","metadata":{"id":"prNx2Sm0WGEj"}},{"cell_type":"markdown","source":"##### 4.3.6 Display the top 10 unigrams by frequency in fake news and plot them as a bar graph  <font color = red>[2.5 marks]</font> <br>","metadata":{"id":"obBKlBVK3mfX"}},{"cell_type":"code","source":"# Print the top 10 unigrams by frequency in fake news and plot the same using a bar graph\n","metadata":{"id":"1qKDzoSIWGXp","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.945025Z","iopub.execute_input":"2025-04-27T12:57:56.945184Z","iopub.status.idle":"2025-04-27T12:57:56.959091Z","shell.execute_reply.started":"2025-04-27T12:57:56.945172Z","shell.execute_reply":"2025-04-27T12:57:56.958404Z"}},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"##### 4.3.7 Display the top 10 bigrams by frequency in fake news and plot them as a bar graph  <font color = red>[2.5 marks]</font> <br>\n\n","metadata":{"id":"bSlMnmqcYsNw"}},{"cell_type":"code","source":"# Print the top 10 bigrams by frequency in fake news and plot the same using a bar graph\n","metadata":{"id":"r5xUk_r9Wa0f","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.959819Z","iopub.execute_input":"2025-04-27T12:57:56.960047Z","iopub.status.idle":"2025-04-27T12:57:56.972532Z","shell.execute_reply.started":"2025-04-27T12:57:56.960033Z","shell.execute_reply":"2025-04-27T12:57:56.971847Z"}},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":"##### 4.3.8 Display the top 10 trigrams by frequency in fake news and plot them as a bar graph  <font color = red>[2.5 marks]</font> <br>\n\n","metadata":{"id":"i08WYIwPYs6R"}},{"cell_type":"code","source":"# Print the top 10 trigrams by frequency in fake news and plot the same using a bar graph\n","metadata":{"id":"6nT9a1EvWa-s","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.973310Z","iopub.execute_input":"2025-04-27T12:57:56.973610Z","iopub.status.idle":"2025-04-27T12:57:56.988481Z","shell.execute_reply.started":"2025-04-27T12:57:56.973588Z","shell.execute_reply":"2025-04-27T12:57:56.987802Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"## **5.** Exploratory Data Analysis on Validation Data [Optional]\n\nPerform EDA on validation data to differentiate EDA on training data with EDA on validation data and the tasks are given below:\n\n<ul>\n  <li> Visualise the data according to the character length of cleaned news text and lemmatized text with POS tags removed\n  <li> Using a word cloud find the top 40 words by frequency in true and fake news separately\n  <li> Find the top unigrams, bigrams and trigrams by frequency in true and fake news separately\n</ul>\n\n\n\n","metadata":{"id":"2VsOO_oHN8-_"}},{"cell_type":"markdown","source":"### **5.1** Visualise character lengths of cleaned news text and lemmatized news text with POS tags removed","metadata":{"id":"jNkif5wrONfI"}},{"cell_type":"markdown","source":"##### 5.1.1  Add new columns to calculate the character lengths of the processed data columns","metadata":{"id":"gAhwSWBWOTIj"}},{"cell_type":"code","source":"# Add a new column to calculate the character length of cleaned news text\n\n# Add a new column to calculate the character length of lemmatized news text with POS tags removed\n","metadata":{"id":"6hYYTrdHORAs","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:56.989223Z","iopub.execute_input":"2025-04-27T12:57:56.990000Z","iopub.status.idle":"2025-04-27T12:57:57.003097Z","shell.execute_reply.started":"2025-04-27T12:57:56.989975Z","shell.execute_reply":"2025-04-27T12:57:57.002383Z"}},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":"##### 5.1.2  Create Histogram to visualise character lengths\n\nPlot both distributions on the same graph for comparison and to observe overlaps and peak differences to understand text preprocessing's impact on text length.","metadata":{"id":"VRILiD8hOX5q"}},{"cell_type":"code","source":"# Create a histogram plot to visualise character lengths\n\n# Add histogram for cleaned news text\n\n# Add histogram for lemmatized news text with POS tags removed\n","metadata":{"id":"j7LLOXC0Oaix","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.003756Z","iopub.execute_input":"2025-04-27T12:57:57.003985Z","iopub.status.idle":"2025-04-27T12:57:57.020227Z","shell.execute_reply.started":"2025-04-27T12:57:57.003970Z","shell.execute_reply":"2025-04-27T12:57:57.019479Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"### **5.2** Find and display the top 40 words by frequency among true and fake news after processing the text","metadata":{"id":"nPxa0JrvOwFu"}},{"cell_type":"markdown","source":"##### 5.2.1  Find and display the top 40 words by frequency among true news in validation data after processing the text","metadata":{"id":"uOZRD8vaFt2h"}},{"cell_type":"code","source":"## Use a word cloud find the top 40 words by frequency among true news after processing the text\n\n# Generate word cloud for True News\n","metadata":{"id":"6_9UVs4WOw0_","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.021068Z","iopub.execute_input":"2025-04-27T12:57:57.021259Z","iopub.status.idle":"2025-04-27T12:57:57.034346Z","shell.execute_reply.started":"2025-04-27T12:57:57.021231Z","shell.execute_reply":"2025-04-27T12:57:57.033670Z"}},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":"##### 5.2.2  Find and display the top 40 words by frequency among fake news in validation data after processing the text","metadata":{"id":"T6AQPITsFuop"}},{"cell_type":"code","source":"## Use a word cloud find the top 40 words by frequency among fake news after processing the text\n\n# Generate word cloud for Fake News\n","metadata":{"id":"4gk6xTdSFu1X","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.035037Z","iopub.execute_input":"2025-04-27T12:57:57.035255Z","iopub.status.idle":"2025-04-27T12:57:57.048200Z","shell.execute_reply.started":"2025-04-27T12:57:57.035240Z","shell.execute_reply":"2025-04-27T12:57:57.047651Z"}},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":"### **5.3** Find and display the top unigrams, bigrams and trigrams by frequency in true news and fake news after processing the text  \n\n\n\n","metadata":{"id":"dx0s2a7xOxKf"}},{"cell_type":"markdown","source":"##### 5.3.1 Write a function to get the specified top n-grams","metadata":{"id":"z2xZKU0RO5ft"}},{"cell_type":"code","source":"## Write a function to get the specified top n-grams\n","metadata":{"id":"g70ZFxcoOxS2","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.048823Z","iopub.execute_input":"2025-04-27T12:57:57.049015Z","iopub.status.idle":"2025-04-27T12:57:57.064308Z","shell.execute_reply.started":"2025-04-27T12:57:57.049001Z","shell.execute_reply":"2025-04-27T12:57:57.063584Z"}},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"##### 5.3.2 Handle the NaN values","metadata":{"id":"k8ud5-r7O7ut"}},{"cell_type":"code","source":"## First handle NaN values in the text data\n","metadata":{"id":"vsBu-aotPBJF","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.064935Z","iopub.execute_input":"2025-04-27T12:57:57.065137Z","iopub.status.idle":"2025-04-27T12:57:57.078601Z","shell.execute_reply.started":"2025-04-27T12:57:57.065123Z","shell.execute_reply":"2025-04-27T12:57:57.078005Z"}},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":"### For True News\n","metadata":{"id":"0KVWcxoDPAiE"}},{"cell_type":"markdown","source":"\n##### 5.3.3 Display the top 10 unigrams by frequency in true news and plot them as a bar graph","metadata":{"id":"Am3uuIlU4wj1"}},{"cell_type":"code","source":"## Print the top 10 unigrams by frequency in true news and plot the same using a bar graph\n","metadata":{"id":"HKdpz-XmPGHD","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.079166Z","iopub.execute_input":"2025-04-27T12:57:57.079323Z","iopub.status.idle":"2025-04-27T12:57:57.093221Z","shell.execute_reply.started":"2025-04-27T12:57:57.079311Z","shell.execute_reply":"2025-04-27T12:57:57.092672Z"}},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":"##### 5.3.4 Display the top 10 bigrams by frequency in true news and plot them as a bar graph","metadata":{"id":"kiKrOL8rPLAs"}},{"cell_type":"code","source":"## Print the top 10 bigrams by frequency in true news and plot the same using a bar graph\n","metadata":{"id":"iuyYGnaNPLwq","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.093834Z","iopub.execute_input":"2025-04-27T12:57:57.093991Z","iopub.status.idle":"2025-04-27T12:57:57.108365Z","shell.execute_reply.started":"2025-04-27T12:57:57.093979Z","shell.execute_reply":"2025-04-27T12:57:57.107852Z"}},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":"##### 5.3.5 Display the top 10 trigrams by frequency in true news and plot them as a bar graph","metadata":{"id":"9f8_h-BiPOKb"}},{"cell_type":"code","source":"## Print the top 10 trigrams by frequency in true news and plot the same using a bar graph\n","metadata":{"id":"8lz-XS7qPQZj","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.109015Z","iopub.execute_input":"2025-04-27T12:57:57.109206Z","iopub.status.idle":"2025-04-27T12:57:57.123285Z","shell.execute_reply.started":"2025-04-27T12:57:57.109192Z","shell.execute_reply":"2025-04-27T12:57:57.122749Z"}},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":"### For Fake News","metadata":{"id":"7MfApeGrd6Fl"}},{"cell_type":"markdown","source":"##### 5.3.6 Display the top 10 unigrams by frequency in fake news and plot them as a bar graph","metadata":{"id":"_CH1csmZeGqh"}},{"cell_type":"code","source":"## Print the top 10 unigrams by frequency in fake news and plot the same using a bar graph\n","metadata":{"id":"w310WzGAeG4K","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.123842Z","iopub.execute_input":"2025-04-27T12:57:57.124033Z","iopub.status.idle":"2025-04-27T12:57:57.137807Z","shell.execute_reply.started":"2025-04-27T12:57:57.124019Z","shell.execute_reply":"2025-04-27T12:57:57.137081Z"}},"outputs":[],"execution_count":52},{"cell_type":"markdown","source":"##### 5.3.7 Display the top 10 bigrams by frequency in fake news and plot them as a bar graph","metadata":{"id":"yFjOaPx7eHFw"}},{"cell_type":"code","source":"## Print the top 10 bigrams by frequency in fake news and plot the same using a bar graph\n","metadata":{"id":"ZuTqnjkIeHSJ","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.138566Z","iopub.execute_input":"2025-04-27T12:57:57.139296Z","iopub.status.idle":"2025-04-27T12:57:57.154822Z","shell.execute_reply.started":"2025-04-27T12:57:57.139270Z","shell.execute_reply":"2025-04-27T12:57:57.154193Z"}},"outputs":[],"execution_count":53},{"cell_type":"markdown","source":"##### 5.3.8 Display the top 10 trigrams by frequency in fake news and plot them as a bar graph","metadata":{"id":"Vn_oiixheHf_"}},{"cell_type":"code","source":"## Print the top 10 trigrams by frequency in fake news and plot the same using a bar graph\n","metadata":{"id":"xduyO4gheHtI","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.155756Z","iopub.execute_input":"2025-04-27T12:57:57.155962Z","iopub.status.idle":"2025-04-27T12:57:57.170088Z","shell.execute_reply.started":"2025-04-27T12:57:57.155948Z","shell.execute_reply":"2025-04-27T12:57:57.169576Z"}},"outputs":[],"execution_count":54},{"cell_type":"markdown","source":"## **6.** Feature Extraction  <font color = red>[10 marks]</font> <br>\n\nFor any ML model to perform classification on textual data, you need to convert it to a vector form. In this assignment, you will use the Word2Vec Vectorizer to create vectors from textual data. Word2Vec model captures the semantic relationship between words.\n","metadata":{"id":"k-I0k0QtJrGA"}},{"cell_type":"markdown","source":"### **6.1** Initialise Word2Vec model  <font color = red>[2 marks]</font>","metadata":{"id":"09xy3mAbtZgZ"}},{"cell_type":"code","source":"## Write your code here to initialise the Word2Vec model by downloading \"word2vec-google-news-300\"\n","metadata":{"id":"Y8fGwaCPJrGA","scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.170670Z","iopub.execute_input":"2025-04-27T12:57:57.170841Z","iopub.status.idle":"2025-04-27T12:57:57.183876Z","shell.execute_reply.started":"2025-04-27T12:57:57.170828Z","shell.execute_reply":"2025-04-27T12:57:57.183300Z"}},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":"### **6.2** Extract vectors for cleaned news data   <font color = red>[8 marks]</font>","metadata":{"id":"yYzD85nTJrGA"}},{"cell_type":"code","source":"## Write your code here to extract the vectors from the Word2Vec model for both training and validation data\n\n\n## Extract the target variable for the training data and validation data\n","metadata":{"id":"ffzdDpp_JrGB","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.184505Z","iopub.execute_input":"2025-04-27T12:57:57.184712Z","iopub.status.idle":"2025-04-27T12:57:57.199727Z","shell.execute_reply.started":"2025-04-27T12:57:57.184696Z","shell.execute_reply":"2025-04-27T12:57:57.198944Z"}},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":"## **7.** Model Training and Evaluation <font color = red>[45 marks]</font>\n\nYou will use a set of supervised models to classify the news into true or fake.","metadata":{"id":"7Q9lwvNEJrGB"}},{"cell_type":"markdown","source":"### **7.0** Import models and evaluation metrics","metadata":{"id":"sO16REK-xpq4"}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report","metadata":{"id":"k0BKoT3wxpq4","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.200452Z","iopub.execute_input":"2025-04-27T12:57:57.200789Z","iopub.status.idle":"2025-04-27T12:57:57.438021Z","shell.execute_reply.started":"2025-04-27T12:57:57.200772Z","shell.execute_reply":"2025-04-27T12:57:57.437403Z"}},"outputs":[],"execution_count":57},{"cell_type":"markdown","source":"### **7.1** Build Logistic Regression Model  <font color = red>[15 marks]</font>","metadata":{"id":"SLuHH1olZXQq"}},{"cell_type":"markdown","source":"##### 7.1.1 Create and train logistic regression model on training data  <font color = red>[10 marks]</font>","metadata":{"id":"b1ItmvvGwduv"}},{"cell_type":"code","source":"## Initialise Logistic Regression model\n\n## Train Logistic Regression model on training data\n\n## Predict on validation data\n","metadata":{"id":"wzXd3YSu5eyY","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.438996Z","iopub.execute_input":"2025-04-27T12:57:57.439205Z","iopub.status.idle":"2025-04-27T12:57:57.442177Z","shell.execute_reply.started":"2025-04-27T12:57:57.439189Z","shell.execute_reply":"2025-04-27T12:57:57.441385Z"}},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":"##### 7.1.2 Calculate and print accuracy, precision, recall and f1-score on validation data <font color = red>[5 marks]</font>","metadata":{"id":"BvNKC8ob8IAL"}},{"cell_type":"code","source":"## Calculate and print accuracy, precision, recall, f1-score on predicted labels\n","metadata":{"id":"BEyQcSoWo4xs","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.442854Z","iopub.execute_input":"2025-04-27T12:57:57.443118Z","iopub.status.idle":"2025-04-27T12:57:57.457901Z","shell.execute_reply.started":"2025-04-27T12:57:57.443102Z","shell.execute_reply":"2025-04-27T12:57:57.457179Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# Classification Report\n","metadata":{"id":"T6P4MA_AC216","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.458628Z","iopub.execute_input":"2025-04-27T12:57:57.458896Z","iopub.status.idle":"2025-04-27T12:57:57.477340Z","shell.execute_reply.started":"2025-04-27T12:57:57.458873Z","shell.execute_reply":"2025-04-27T12:57:57.476624Z"}},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":"### **7.2** Build Decision Tree Model <font color = red>[15 marks]</font>","metadata":{"id":"TRGPMQZd8r8B"}},{"cell_type":"markdown","source":"##### 7.2.1 Create and train a decision tree model on training data <font color = red>[10 marks]</font>","metadata":{"id":"Rgv4vqrt81sH"}},{"cell_type":"code","source":"## Initialise Decision Tree model\n\n## Train Decision Tree model on training data\n\n## Predict on validation data\n","metadata":{"id":"i-mTab94xpq4","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.478148Z","iopub.execute_input":"2025-04-27T12:57:57.478337Z","iopub.status.idle":"2025-04-27T12:57:57.491904Z","shell.execute_reply.started":"2025-04-27T12:57:57.478323Z","shell.execute_reply":"2025-04-27T12:57:57.491304Z"}},"outputs":[],"execution_count":61},{"cell_type":"markdown","source":"##### 7.2.2 Calculate and print accuracy, precision, recall and f1-score on validation data <font color = red>[5 marks]</font>","metadata":{"id":"vZ_Vj5fs6w9I"}},{"cell_type":"code","source":"## Calculate and print accuracy, precision, recall, f1-score on predicted labels\n","metadata":{"id":"15iYiCQhp7jo","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.492476Z","iopub.execute_input":"2025-04-27T12:57:57.492644Z","iopub.status.idle":"2025-04-27T12:57:57.506059Z","shell.execute_reply.started":"2025-04-27T12:57:57.492631Z","shell.execute_reply":"2025-04-27T12:57:57.505458Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"# Classification Report\n","metadata":{"id":"DohNckxxxpq4","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.506800Z","iopub.execute_input":"2025-04-27T12:57:57.507020Z","iopub.status.idle":"2025-04-27T12:57:57.520042Z","shell.execute_reply.started":"2025-04-27T12:57:57.506998Z","shell.execute_reply":"2025-04-27T12:57:57.519432Z"}},"outputs":[],"execution_count":63},{"cell_type":"markdown","source":"### **7.3** Build Random Forest Model <font color = red>[15 marks]</font>\n","metadata":{"id":"xnB_P9kd9EdC"}},{"cell_type":"markdown","source":"##### 7.3.1 Create and train a random forest model on training data <font color = red>[10 marks]</font>","metadata":{"id":"DhW0nyU29In9"}},{"cell_type":"code","source":"## Initialise Random Forest model\n\n## Train Random Forest model on training data\n\n## Predict on validation data\n","metadata":{"id":"uIvY9-oPxpq4","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.520773Z","iopub.execute_input":"2025-04-27T12:57:57.521032Z","iopub.status.idle":"2025-04-27T12:57:57.533613Z","shell.execute_reply.started":"2025-04-27T12:57:57.521010Z","shell.execute_reply":"2025-04-27T12:57:57.532976Z"}},"outputs":[],"execution_count":64},{"cell_type":"markdown","source":" ##### 7.3.2 Calculate and print accuracy, precision, recall and f1-score on validation data <font color = red>[5 marks]</font>","metadata":{"id":"RRBxZieM7eea"}},{"cell_type":"code","source":"## Calculate and print accuracy, precision, recall, f1-score on predicted labels\n","metadata":{"id":"VzNK3jcCq01-","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.534189Z","iopub.execute_input":"2025-04-27T12:57:57.534346Z","iopub.status.idle":"2025-04-27T12:57:57.548155Z","shell.execute_reply.started":"2025-04-27T12:57:57.534334Z","shell.execute_reply":"2025-04-27T12:57:57.547418Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# Classification Report\n","metadata":{"id":"VIBCo_kFxpq4","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T12:57:57.548978Z","iopub.execute_input":"2025-04-27T12:57:57.549136Z","iopub.status.idle":"2025-04-27T12:57:57.565052Z","shell.execute_reply.started":"2025-04-27T12:57:57.549124Z","shell.execute_reply":"2025-04-27T12:57:57.564280Z"}},"outputs":[],"execution_count":66},{"cell_type":"markdown","source":"## **8.** Conclusion <font color = red>[5 marks]</font>\n\nSummarise your findings by discussing patterns observed in true and fake news and how semantic classification addressed the problem. Highlight the best model chosen, the evaluation metric prioritised for the decision, and assess the approach and its impact.","metadata":{"id":"Lnj7RUDDSEJX"}}]}